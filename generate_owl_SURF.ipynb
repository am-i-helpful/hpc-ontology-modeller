{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-08-21T22:37:50.449465700Z",
     "start_time": "2023-08-21T22:37:50.230711300Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pyarrow.parquet as pq\n",
    "from owlready2 import *\n",
    "import urllib.parse\n",
    "# import os\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "outputs": [],
   "source": [
    "# number of rows to be considered from the parquet file, as all rows can't be considered because of the huge size of the HPC workload\n",
    "number_of_rows = 10\n",
    "# Source of the data - data shared by SURF team\n",
    "base_dir = \"C:/GDrive-Shekhar/Literature Study/Xiaoyu-Shared/SURF/\""
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-21T22:37:50.543238400Z",
     "start_time": "2023-08-21T22:37:50.230711300Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "outputs": [
    {
     "data": {
      "text/plain": "         id           timestamp    node  node_time_seconds  node_load15  \\\n0  23499351 2022-08-01 23:00:30  r12n20       1.659390e+09         3.25   \n1  24679115 2022-08-01 23:00:30   r10n1       1.659390e+09        16.04   \n2  24681081 2022-08-01 23:00:30   r10n2       1.659390e+09        16.06   \n3  24683047 2022-08-01 23:00:30   r10n3       1.659390e+09        10.05   \n4  24685012 2022-08-01 23:00:30   r10n4       1.659390e+09        16.07   \n5  24686977 2022-08-01 23:00:30   r10n5       1.659390e+09        10.72   \n6  24688943 2022-08-01 23:00:30   r10n6       1.659390e+09         0.00   \n7  24690909 2022-08-01 23:00:30   r10n7       1.659390e+09        15.00   \n8  24692875 2022-08-01 23:00:30   r10n8       1.659390e+09         0.43   \n9  24694841 2022-08-01 23:00:30   r10n9       1.659390e+09        15.00   \n\n   surfsara_power_usage   up  node_netstat_Tcp_OutSegs  \\\n0                 180.0  1.0              8.229440e+09   \n1                 136.0  1.0              4.435130e+09   \n2                 184.0  1.0              1.333230e+10   \n3                 160.0  1.0              7.411810e+09   \n4                 152.0  1.0              3.827420e+09   \n5                 176.0  1.0              4.021590e+09   \n6                  36.0  1.0              3.613030e+09   \n7                 180.0  1.0              3.387300e+09   \n8                  52.0  1.0              3.366060e+09   \n9                 164.0  1.0              1.221040e+10   \n\n   node_netstat_Tcp_InErrs  node_context_switches_total  ...  \\\n0                      0.0                 2.358430e+10  ...   \n1                      0.0                 4.385200e+10  ...   \n2                      0.0                 6.533210e+10  ...   \n3                      0.0                 3.398420e+10  ...   \n4                      0.0                 5.320250e+10  ...   \n5                      0.0                 8.578120e+09  ...   \n6                      0.0                 5.877550e+10  ...   \n7                      0.0                 7.489570e+10  ...   \n8                      8.0                 2.973960e+10  ...   \n9                      0.0                 4.480610e+10  ...   \n\n   nvidia_gpu_duty_cycle-mean  nvidia_gpu_duty_cycle-max  \\\n0                         NaN                        NaN   \n1                         NaN                        NaN   \n2                         NaN                        NaN   \n3                         NaN                        NaN   \n4                         NaN                        NaN   \n5                         NaN                        NaN   \n6                         NaN                        NaN   \n7                         NaN                        NaN   \n8                         NaN                        NaN   \n9                         NaN                        NaN   \n\n   node_network_transmit_packets_total-sum  node_udp_queues-sum  \\\n0                             8.304228e+09                  0.0   \n1                             4.443808e+09                  0.0   \n2                             1.335061e+10                  0.0   \n3                             7.423408e+09                  0.0   \n4                             3.835132e+09                  0.0   \n5                             4.028638e+09                  0.0   \n6                             3.620775e+09                  0.0   \n7                             3.395939e+09                  0.0   \n8                             3.375636e+09                  0.0   \n9                             1.223325e+10                  0.0   \n\n   node_network_receive_bytes_total-sum  \\\n0                          3.904484e+13   \n1                          1.629571e+13   \n2                          6.950092e+13   \n3                          4.388573e+13   \n4                          1.695007e+13   \n5                          1.673817e+13   \n6                          1.694239e+13   \n7                          1.406663e+13   \n8                          1.158139e+13   \n9                          5.315886e+13   \n\n   node_network_receive_packets_total-sum  \\\n0                            8.240601e+09   \n1                            4.457970e+09   \n2                            1.388512e+10   \n3                            7.515447e+09   \n4                            3.949527e+09   \n5                            4.262980e+09   \n6                            3.839891e+09   \n7                            3.583665e+09   \n8                            3.305960e+09   \n9                            1.245858e+10   \n\n   node_network_receive_multicast_total-sum  node_disk_io_now-sum  \\\n0                                       1.0                   0.0   \n1                                       2.0                   0.0   \n2                                       2.0                   0.0   \n3                                       2.0                   0.0   \n4                                       2.0                   0.0   \n5                                       2.0                   0.0   \n6                                       2.0                   0.0   \n7                                       2.0                   0.0   \n8                                       2.0                   0.0   \n9                                       2.0                   0.0   \n\n   node_rapl_package_joules_total-sum  node_network_receive_drop_total-sum  \n0                            95773.30                                  0.0  \n1                           246806.22                                  0.0  \n2                           215142.45                                  0.0  \n3                           180487.40                                  0.0  \n4                           143603.09                                  0.0  \n5                           155978.26                                  0.0  \n6                           226003.76                                  0.0  \n7                            42950.88                                  0.0  \n8                           237935.83                                  0.0  \n9                           258069.61                                  0.0  \n\n[10 rows x 69 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>timestamp</th>\n      <th>node</th>\n      <th>node_time_seconds</th>\n      <th>node_load15</th>\n      <th>surfsara_power_usage</th>\n      <th>up</th>\n      <th>node_netstat_Tcp_OutSegs</th>\n      <th>node_netstat_Tcp_InErrs</th>\n      <th>node_context_switches_total</th>\n      <th>...</th>\n      <th>nvidia_gpu_duty_cycle-mean</th>\n      <th>nvidia_gpu_duty_cycle-max</th>\n      <th>node_network_transmit_packets_total-sum</th>\n      <th>node_udp_queues-sum</th>\n      <th>node_network_receive_bytes_total-sum</th>\n      <th>node_network_receive_packets_total-sum</th>\n      <th>node_network_receive_multicast_total-sum</th>\n      <th>node_disk_io_now-sum</th>\n      <th>node_rapl_package_joules_total-sum</th>\n      <th>node_network_receive_drop_total-sum</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>23499351</td>\n      <td>2022-08-01 23:00:30</td>\n      <td>r12n20</td>\n      <td>1.659390e+09</td>\n      <td>3.25</td>\n      <td>180.0</td>\n      <td>1.0</td>\n      <td>8.229440e+09</td>\n      <td>0.0</td>\n      <td>2.358430e+10</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>8.304228e+09</td>\n      <td>0.0</td>\n      <td>3.904484e+13</td>\n      <td>8.240601e+09</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>95773.30</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>24679115</td>\n      <td>2022-08-01 23:00:30</td>\n      <td>r10n1</td>\n      <td>1.659390e+09</td>\n      <td>16.04</td>\n      <td>136.0</td>\n      <td>1.0</td>\n      <td>4.435130e+09</td>\n      <td>0.0</td>\n      <td>4.385200e+10</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>4.443808e+09</td>\n      <td>0.0</td>\n      <td>1.629571e+13</td>\n      <td>4.457970e+09</td>\n      <td>2.0</td>\n      <td>0.0</td>\n      <td>246806.22</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>24681081</td>\n      <td>2022-08-01 23:00:30</td>\n      <td>r10n2</td>\n      <td>1.659390e+09</td>\n      <td>16.06</td>\n      <td>184.0</td>\n      <td>1.0</td>\n      <td>1.333230e+10</td>\n      <td>0.0</td>\n      <td>6.533210e+10</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>1.335061e+10</td>\n      <td>0.0</td>\n      <td>6.950092e+13</td>\n      <td>1.388512e+10</td>\n      <td>2.0</td>\n      <td>0.0</td>\n      <td>215142.45</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>24683047</td>\n      <td>2022-08-01 23:00:30</td>\n      <td>r10n3</td>\n      <td>1.659390e+09</td>\n      <td>10.05</td>\n      <td>160.0</td>\n      <td>1.0</td>\n      <td>7.411810e+09</td>\n      <td>0.0</td>\n      <td>3.398420e+10</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>7.423408e+09</td>\n      <td>0.0</td>\n      <td>4.388573e+13</td>\n      <td>7.515447e+09</td>\n      <td>2.0</td>\n      <td>0.0</td>\n      <td>180487.40</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>24685012</td>\n      <td>2022-08-01 23:00:30</td>\n      <td>r10n4</td>\n      <td>1.659390e+09</td>\n      <td>16.07</td>\n      <td>152.0</td>\n      <td>1.0</td>\n      <td>3.827420e+09</td>\n      <td>0.0</td>\n      <td>5.320250e+10</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>3.835132e+09</td>\n      <td>0.0</td>\n      <td>1.695007e+13</td>\n      <td>3.949527e+09</td>\n      <td>2.0</td>\n      <td>0.0</td>\n      <td>143603.09</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>24686977</td>\n      <td>2022-08-01 23:00:30</td>\n      <td>r10n5</td>\n      <td>1.659390e+09</td>\n      <td>10.72</td>\n      <td>176.0</td>\n      <td>1.0</td>\n      <td>4.021590e+09</td>\n      <td>0.0</td>\n      <td>8.578120e+09</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>4.028638e+09</td>\n      <td>0.0</td>\n      <td>1.673817e+13</td>\n      <td>4.262980e+09</td>\n      <td>2.0</td>\n      <td>0.0</td>\n      <td>155978.26</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>24688943</td>\n      <td>2022-08-01 23:00:30</td>\n      <td>r10n6</td>\n      <td>1.659390e+09</td>\n      <td>0.00</td>\n      <td>36.0</td>\n      <td>1.0</td>\n      <td>3.613030e+09</td>\n      <td>0.0</td>\n      <td>5.877550e+10</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>3.620775e+09</td>\n      <td>0.0</td>\n      <td>1.694239e+13</td>\n      <td>3.839891e+09</td>\n      <td>2.0</td>\n      <td>0.0</td>\n      <td>226003.76</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>24690909</td>\n      <td>2022-08-01 23:00:30</td>\n      <td>r10n7</td>\n      <td>1.659390e+09</td>\n      <td>15.00</td>\n      <td>180.0</td>\n      <td>1.0</td>\n      <td>3.387300e+09</td>\n      <td>0.0</td>\n      <td>7.489570e+10</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>3.395939e+09</td>\n      <td>0.0</td>\n      <td>1.406663e+13</td>\n      <td>3.583665e+09</td>\n      <td>2.0</td>\n      <td>0.0</td>\n      <td>42950.88</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>24692875</td>\n      <td>2022-08-01 23:00:30</td>\n      <td>r10n8</td>\n      <td>1.659390e+09</td>\n      <td>0.43</td>\n      <td>52.0</td>\n      <td>1.0</td>\n      <td>3.366060e+09</td>\n      <td>8.0</td>\n      <td>2.973960e+10</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>3.375636e+09</td>\n      <td>0.0</td>\n      <td>1.158139e+13</td>\n      <td>3.305960e+09</td>\n      <td>2.0</td>\n      <td>0.0</td>\n      <td>237935.83</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>24694841</td>\n      <td>2022-08-01 23:00:30</td>\n      <td>r10n9</td>\n      <td>1.659390e+09</td>\n      <td>15.00</td>\n      <td>164.0</td>\n      <td>1.0</td>\n      <td>1.221040e+10</td>\n      <td>0.0</td>\n      <td>4.480610e+10</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>1.223325e+10</td>\n      <td>0.0</td>\n      <td>5.315886e+13</td>\n      <td>1.245858e+10</td>\n      <td>2.0</td>\n      <td>0.0</td>\n      <td>258069.61</td>\n      <td>0.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>10 rows × 69 columns</p>\n</div>"
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# SURF dataset\n",
    "file_surf = base_dir + \"prometheus_part-00000-d7afaa0c-ea3a-45f1-9f01-d2d20bffbb9c-c000.snappy.parquet\"\n",
    "df_surf = pq.read_table(source=file_surf).to_pandas()\n",
    "# df_gv100card0 = df_gv100card0.sort_values('node').head(number_of_rows)\n",
    "df_surf.head(number_of_rows)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-21T22:37:50.715132100Z",
     "start_time": "2023-08-21T22:37:50.246363700Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "outputs": [
    {
     "data": {
      "text/plain": "   id          start_date            end_date    node  nodetypes numnodes  \\\n0   1 2021-12-26 22:06:31 2021-12-31 22:06:50   r13n5  normal(1)        1   \n1   2 2021-12-26 22:06:43 2021-12-31 22:06:50  r14n27  normal(1)        1   \n2   3 2021-12-26 22:06:43 2021-12-31 22:06:50  r15n12  normal(1)        1   \n3   4 2021-12-26 22:06:43 2021-12-31 22:06:50  r10n14  normal(1)        1   \n4   5 2021-12-26 22:06:43 2021-12-31 22:06:50  r10n30  normal(1)        1   \n5   6 2021-12-26 22:06:43 2021-12-31 22:06:50  r11n16  normal(1)        1   \n6   7 2021-12-26 22:07:31 2021-12-31 22:07:50   r26n8  normal(1)        1   \n7   8 2021-12-26 22:29:04 2021-12-31 22:29:20  r12n24  normal(1)        1   \n8   9 2021-12-26 22:07:31 2021-12-31 22:07:50  r10n29  normal(1)        1   \n9  10 2021-12-26 22:07:31 2021-12-31 22:07:50   r11n4  normal(1)        1   \n\n  numcores sharednode      submit       start         end    state exitcode  \\\n0       16          0  1640538678  1640559991  1640992010  TIMEOUT      0:0   \n1       16          0  1640538678  1640560003  1640992010  TIMEOUT      0:0   \n2       16          0  1640538678  1640560003  1640992010  TIMEOUT      0:0   \n3       16          0  1640538678  1640560003  1640992010  TIMEOUT      0:0   \n4       16          0  1640538678  1640560003  1640992010  TIMEOUT      0:0   \n5       16          0  1640538678  1640560003  1640992010  TIMEOUT      0:0   \n6       16          0  1640538678  1640560051  1640992070  TIMEOUT      0:0   \n7       16          0  1640538678  1640561344  1640993360  TIMEOUT      0:0   \n8       16          0  1640538678  1640560051  1640992070  TIMEOUT      0:0   \n9       16          0  1640538678  1640560051  1640992070  TIMEOUT      0:0   \n\n  reservation partprepaid  \n0                       0  \n1                       0  \n2                       0  \n3                       0  \n4                       0  \n5                       0  \n6                       0  \n7                       0  \n8                       0  \n9                       0  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>start_date</th>\n      <th>end_date</th>\n      <th>node</th>\n      <th>nodetypes</th>\n      <th>numnodes</th>\n      <th>numcores</th>\n      <th>sharednode</th>\n      <th>submit</th>\n      <th>start</th>\n      <th>end</th>\n      <th>state</th>\n      <th>exitcode</th>\n      <th>reservation</th>\n      <th>partprepaid</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>2021-12-26 22:06:31</td>\n      <td>2021-12-31 22:06:50</td>\n      <td>r13n5</td>\n      <td>normal(1)</td>\n      <td>1</td>\n      <td>16</td>\n      <td>0</td>\n      <td>1640538678</td>\n      <td>1640559991</td>\n      <td>1640992010</td>\n      <td>TIMEOUT</td>\n      <td>0:0</td>\n      <td></td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>2021-12-26 22:06:43</td>\n      <td>2021-12-31 22:06:50</td>\n      <td>r14n27</td>\n      <td>normal(1)</td>\n      <td>1</td>\n      <td>16</td>\n      <td>0</td>\n      <td>1640538678</td>\n      <td>1640560003</td>\n      <td>1640992010</td>\n      <td>TIMEOUT</td>\n      <td>0:0</td>\n      <td></td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>2021-12-26 22:06:43</td>\n      <td>2021-12-31 22:06:50</td>\n      <td>r15n12</td>\n      <td>normal(1)</td>\n      <td>1</td>\n      <td>16</td>\n      <td>0</td>\n      <td>1640538678</td>\n      <td>1640560003</td>\n      <td>1640992010</td>\n      <td>TIMEOUT</td>\n      <td>0:0</td>\n      <td></td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>2021-12-26 22:06:43</td>\n      <td>2021-12-31 22:06:50</td>\n      <td>r10n14</td>\n      <td>normal(1)</td>\n      <td>1</td>\n      <td>16</td>\n      <td>0</td>\n      <td>1640538678</td>\n      <td>1640560003</td>\n      <td>1640992010</td>\n      <td>TIMEOUT</td>\n      <td>0:0</td>\n      <td></td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5</td>\n      <td>2021-12-26 22:06:43</td>\n      <td>2021-12-31 22:06:50</td>\n      <td>r10n30</td>\n      <td>normal(1)</td>\n      <td>1</td>\n      <td>16</td>\n      <td>0</td>\n      <td>1640538678</td>\n      <td>1640560003</td>\n      <td>1640992010</td>\n      <td>TIMEOUT</td>\n      <td>0:0</td>\n      <td></td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>6</td>\n      <td>2021-12-26 22:06:43</td>\n      <td>2021-12-31 22:06:50</td>\n      <td>r11n16</td>\n      <td>normal(1)</td>\n      <td>1</td>\n      <td>16</td>\n      <td>0</td>\n      <td>1640538678</td>\n      <td>1640560003</td>\n      <td>1640992010</td>\n      <td>TIMEOUT</td>\n      <td>0:0</td>\n      <td></td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>7</td>\n      <td>2021-12-26 22:07:31</td>\n      <td>2021-12-31 22:07:50</td>\n      <td>r26n8</td>\n      <td>normal(1)</td>\n      <td>1</td>\n      <td>16</td>\n      <td>0</td>\n      <td>1640538678</td>\n      <td>1640560051</td>\n      <td>1640992070</td>\n      <td>TIMEOUT</td>\n      <td>0:0</td>\n      <td></td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>8</td>\n      <td>2021-12-26 22:29:04</td>\n      <td>2021-12-31 22:29:20</td>\n      <td>r12n24</td>\n      <td>normal(1)</td>\n      <td>1</td>\n      <td>16</td>\n      <td>0</td>\n      <td>1640538678</td>\n      <td>1640561344</td>\n      <td>1640993360</td>\n      <td>TIMEOUT</td>\n      <td>0:0</td>\n      <td></td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>9</td>\n      <td>2021-12-26 22:07:31</td>\n      <td>2021-12-31 22:07:50</td>\n      <td>r10n29</td>\n      <td>normal(1)</td>\n      <td>1</td>\n      <td>16</td>\n      <td>0</td>\n      <td>1640538678</td>\n      <td>1640560051</td>\n      <td>1640992070</td>\n      <td>TIMEOUT</td>\n      <td>0:0</td>\n      <td></td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>10</td>\n      <td>2021-12-26 22:07:31</td>\n      <td>2021-12-31 22:07:50</td>\n      <td>r11n4</td>\n      <td>normal(1)</td>\n      <td>1</td>\n      <td>16</td>\n      <td>0</td>\n      <td>1640538678</td>\n      <td>1640560051</td>\n      <td>1640992070</td>\n      <td>TIMEOUT</td>\n      <td>0:0</td>\n      <td></td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# SURF dataset\n",
    "file_surf_slurm = base_dir + \"split_slurm_table.parquet\"\n",
    "df_surf_slurm = pq.read_table(source=file_surf_slurm).to_pandas()\n",
    "# df_gv100card0 = df_gv100card0.sort_values('node').head(number_of_rows)\n",
    "df_surf_slurm.head(number_of_rows)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-21T22:37:53.176890300Z",
     "start_time": "2023-08-21T22:37:50.715132100Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id\n",
      "node\n",
      "node_arp_entries-sum\n",
      "node_boot_time_seconds\n",
      "node_context_switches_total\n",
      "node_disk_io_now-sum\n",
      "node_disk_read_bytes_total-sum\n",
      "node_disk_writes_completed_total-sum\n",
      "node_disk_written_bytes_total-sum\n",
      "node_filesystem_avail_bytes-sum\n",
      "node_filesystem_device_error-sum\n",
      "node_filesystem_files-sum\n",
      "node_filesystem_files_free-sum\n",
      "node_filesystem_free_bytes-sum\n",
      "node_filesystem_size_bytes-sum\n",
      "node_forks_total\n",
      "node_hwmon_temp_celsius-max\n",
      "node_hwmon_temp_celsius-mean\n",
      "node_hwmon_temp_celsius-min\n",
      "node_intr_total\n",
      "node_load1\n",
      "node_load15\n",
      "node_load5\n",
      "node_memory_Active_bytes\n",
      "node_memory_Dirty_bytes\n",
      "node_memory_MemFree_bytes\n",
      "node_memory_Percpu_bytes\n",
      "node_netstat_Icmp_InErrors\n",
      "node_netstat_Icmp_InMsgs\n",
      "node_netstat_Icmp_OutMsgs\n",
      "node_netstat_Tcp_InErrs\n",
      "node_netstat_Tcp_InSegs\n",
      "node_netstat_Tcp_OutSegs\n",
      "node_netstat_Tcp_RetransSegs\n",
      "node_netstat_Udp_InDatagrams\n",
      "node_netstat_Udp_InErrors\n",
      "node_netstat_Udp_OutDatagrams\n",
      "node_network_receive_bytes_total-sum\n",
      "node_network_receive_drop_total-sum\n",
      "node_network_receive_multicast_total-sum\n",
      "node_network_receive_packets_total-sum\n",
      "node_network_transmit_bytes_total-sum\n",
      "node_network_transmit_packets_total-sum\n",
      "node_procs_blocked\n",
      "node_procs_running\n",
      "node_rapl_package_joules_total-sum\n",
      "node_thermal_zone_temp-max\n",
      "node_thermal_zone_temp-mean\n",
      "node_thermal_zone_temp-min\n",
      "node_time_seconds\n",
      "node_udp_queues-sum\n",
      "nvidia_gpu_duty_cycle-max\n",
      "nvidia_gpu_duty_cycle-mean\n",
      "nvidia_gpu_duty_cycle-min\n",
      "nvidia_gpu_fanspeed_percent-max\n",
      "nvidia_gpu_fanspeed_percent-mean\n",
      "nvidia_gpu_fanspeed_percent-min\n",
      "nvidia_gpu_memory_used_bytes-sum\n",
      "nvidia_gpu_power_usage_milliwatts-max\n",
      "nvidia_gpu_power_usage_milliwatts-mean\n",
      "nvidia_gpu_power_usage_milliwatts-min\n",
      "nvidia_gpu_power_usage_milliwatts-sum\n",
      "nvidia_gpu_temperature_celsius-max\n",
      "nvidia_gpu_temperature_celsius-mean\n",
      "nvidia_gpu_temperature_celsius-min\n",
      "surfsara_ambient_temp\n",
      "surfsara_power_usage\n",
      "timestamp\n",
      "up\n"
     ]
    }
   ],
   "source": [
    "columns = list(df_surf)\n",
    "columns.sort()\n",
    "for element in columns:\n",
    "    print(element)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-21T22:37:53.231615600Z",
     "start_time": "2023-08-21T22:37:53.176890300Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id\n",
      "start_date\n",
      "end_date\n",
      "node\n",
      "nodetypes\n",
      "numnodes\n",
      "numcores\n",
      "sharednode\n",
      "submit\n",
      "start\n",
      "end\n",
      "state\n",
      "exitcode\n",
      "reservation\n",
      "partprepaid\n"
     ]
    }
   ],
   "source": [
    "columns_slurm = list(df_surf_slurm)\n",
    "# columns_slurm.sort()\n",
    "for element in columns_slurm:\n",
    "    print(element)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-21T22:37:53.231615600Z",
     "start_time": "2023-08-21T22:37:53.192516100Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "outputs": [
    {
     "data": {
      "text/plain": "         id           timestamp    node  node_time_seconds  node_load15  \\\n0  23499351 2022-08-01 23:00:30  r12n20       1.659390e+09         3.25   \n1  24679115 2022-08-01 23:00:30   r10n1       1.659390e+09        16.04   \n2  24681081 2022-08-01 23:00:30   r10n2       1.659390e+09        16.06   \n3  24683047 2022-08-01 23:00:30   r10n3       1.659390e+09        10.05   \n4  24685012 2022-08-01 23:00:30   r10n4       1.659390e+09        16.07   \n\n   surfsara_power_usage   up  node_netstat_Tcp_OutSegs  \\\n0                 180.0  1.0              8.229440e+09   \n1                 136.0  1.0              4.435130e+09   \n2                 184.0  1.0              1.333230e+10   \n3                 160.0  1.0              7.411810e+09   \n4                 152.0  1.0              3.827420e+09   \n\n   node_netstat_Tcp_InErrs  node_context_switches_total  ...  \\\n0                      0.0                 2.358430e+10  ...   \n1                      0.0                 4.385200e+10  ...   \n2                      0.0                 6.533210e+10  ...   \n3                      0.0                 3.398420e+10  ...   \n4                      0.0                 5.320250e+10  ...   \n\n   node_network_transmit_packets_total-sum  node_udp_queues-sum  \\\n0                             8.304228e+09                  0.0   \n1                             4.443808e+09                  0.0   \n2                             1.335061e+10                  0.0   \n3                             7.423408e+09                  0.0   \n4                             3.835132e+09                  0.0   \n\n   node_network_receive_bytes_total-sum  \\\n0                          3.904484e+13   \n1                          1.629571e+13   \n2                          6.950092e+13   \n3                          4.388573e+13   \n4                          1.695007e+13   \n\n   node_network_receive_packets_total-sum  \\\n0                            8.240601e+09   \n1                            4.457970e+09   \n2                            1.388512e+10   \n3                            7.515447e+09   \n4                            3.949527e+09   \n\n   node_network_receive_multicast_total-sum  node_disk_io_now-sum  \\\n0                                       1.0                   0.0   \n1                                       2.0                   0.0   \n2                                       2.0                   0.0   \n3                                       2.0                   0.0   \n4                                       2.0                   0.0   \n\n   node_rapl_package_joules_total-sum  node_network_receive_drop_total-sum  \\\n0                            95773.30                                  0.0   \n1                           246806.22                                  0.0   \n2                           215142.45                                  0.0   \n3                           180487.40                                  0.0   \n4                           143603.09                                  0.0   \n\n   node_num_in_rack  rack  \n0                20    12  \n1                 1    10  \n2                 2    10  \n3                 3    10  \n4                 4    10  \n\n[5 rows x 71 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>timestamp</th>\n      <th>node</th>\n      <th>node_time_seconds</th>\n      <th>node_load15</th>\n      <th>surfsara_power_usage</th>\n      <th>up</th>\n      <th>node_netstat_Tcp_OutSegs</th>\n      <th>node_netstat_Tcp_InErrs</th>\n      <th>node_context_switches_total</th>\n      <th>...</th>\n      <th>node_network_transmit_packets_total-sum</th>\n      <th>node_udp_queues-sum</th>\n      <th>node_network_receive_bytes_total-sum</th>\n      <th>node_network_receive_packets_total-sum</th>\n      <th>node_network_receive_multicast_total-sum</th>\n      <th>node_disk_io_now-sum</th>\n      <th>node_rapl_package_joules_total-sum</th>\n      <th>node_network_receive_drop_total-sum</th>\n      <th>node_num_in_rack</th>\n      <th>rack</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>23499351</td>\n      <td>2022-08-01 23:00:30</td>\n      <td>r12n20</td>\n      <td>1.659390e+09</td>\n      <td>3.25</td>\n      <td>180.0</td>\n      <td>1.0</td>\n      <td>8.229440e+09</td>\n      <td>0.0</td>\n      <td>2.358430e+10</td>\n      <td>...</td>\n      <td>8.304228e+09</td>\n      <td>0.0</td>\n      <td>3.904484e+13</td>\n      <td>8.240601e+09</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>95773.30</td>\n      <td>0.0</td>\n      <td>20</td>\n      <td>12</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>24679115</td>\n      <td>2022-08-01 23:00:30</td>\n      <td>r10n1</td>\n      <td>1.659390e+09</td>\n      <td>16.04</td>\n      <td>136.0</td>\n      <td>1.0</td>\n      <td>4.435130e+09</td>\n      <td>0.0</td>\n      <td>4.385200e+10</td>\n      <td>...</td>\n      <td>4.443808e+09</td>\n      <td>0.0</td>\n      <td>1.629571e+13</td>\n      <td>4.457970e+09</td>\n      <td>2.0</td>\n      <td>0.0</td>\n      <td>246806.22</td>\n      <td>0.0</td>\n      <td>1</td>\n      <td>10</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>24681081</td>\n      <td>2022-08-01 23:00:30</td>\n      <td>r10n2</td>\n      <td>1.659390e+09</td>\n      <td>16.06</td>\n      <td>184.0</td>\n      <td>1.0</td>\n      <td>1.333230e+10</td>\n      <td>0.0</td>\n      <td>6.533210e+10</td>\n      <td>...</td>\n      <td>1.335061e+10</td>\n      <td>0.0</td>\n      <td>6.950092e+13</td>\n      <td>1.388512e+10</td>\n      <td>2.0</td>\n      <td>0.0</td>\n      <td>215142.45</td>\n      <td>0.0</td>\n      <td>2</td>\n      <td>10</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>24683047</td>\n      <td>2022-08-01 23:00:30</td>\n      <td>r10n3</td>\n      <td>1.659390e+09</td>\n      <td>10.05</td>\n      <td>160.0</td>\n      <td>1.0</td>\n      <td>7.411810e+09</td>\n      <td>0.0</td>\n      <td>3.398420e+10</td>\n      <td>...</td>\n      <td>7.423408e+09</td>\n      <td>0.0</td>\n      <td>4.388573e+13</td>\n      <td>7.515447e+09</td>\n      <td>2.0</td>\n      <td>0.0</td>\n      <td>180487.40</td>\n      <td>0.0</td>\n      <td>3</td>\n      <td>10</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>24685012</td>\n      <td>2022-08-01 23:00:30</td>\n      <td>r10n4</td>\n      <td>1.659390e+09</td>\n      <td>16.07</td>\n      <td>152.0</td>\n      <td>1.0</td>\n      <td>3.827420e+09</td>\n      <td>0.0</td>\n      <td>5.320250e+10</td>\n      <td>...</td>\n      <td>3.835132e+09</td>\n      <td>0.0</td>\n      <td>1.695007e+13</td>\n      <td>3.949527e+09</td>\n      <td>2.0</td>\n      <td>0.0</td>\n      <td>143603.09</td>\n      <td>0.0</td>\n      <td>4</td>\n      <td>10</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 71 columns</p>\n</div>"
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_surf_reduced = df_surf.head(5)\n",
    "df_surf_reduced\n",
    "df_surf_reduced_copy = df_surf_reduced.copy()\n",
    "start = 'r'\n",
    "end = 'n'\n",
    "# create node and rack designations in the data-frame\n",
    "df_surf_reduced_copy['node_num_in_rack'] = df_surf_reduced_copy['node'].apply(lambda x: x[x.find(end)+1:])\n",
    "df_surf_reduced_copy['rack'] = df_surf_reduced_copy['node'].apply(lambda x: x[x.find(start)+1:x.find(end)])\n",
    "# Print the final reduced dataframe\n",
    "df_surf_reduced_copy"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-21T22:37:53.372242600Z",
     "start_time": "2023-08-21T22:37:53.200359100Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "outputs": [
    {
     "data": {
      "text/plain": "   id          start_date            end_date    node  nodetypes numnodes  \\\n0   1 2021-12-26 22:06:31 2021-12-31 22:06:50   r13n5  normal(1)        1   \n1   2 2021-12-26 22:06:43 2021-12-31 22:06:50  r14n27  normal(1)        1   \n2   3 2021-12-26 22:06:43 2021-12-31 22:06:50  r15n12  normal(1)        1   \n3   4 2021-12-26 22:06:43 2021-12-31 22:06:50  r10n14  normal(1)        1   \n4   5 2021-12-26 22:06:43 2021-12-31 22:06:50  r10n30  normal(1)        1   \n\n  numcores sharednode      submit       start         end    state exitcode  \\\n0       16          0  1640538678  1640559991  1640992010  TIMEOUT      0:0   \n1       16          0  1640538678  1640560003  1640992010  TIMEOUT      0:0   \n2       16          0  1640538678  1640560003  1640992010  TIMEOUT      0:0   \n3       16          0  1640538678  1640560003  1640992010  TIMEOUT      0:0   \n4       16          0  1640538678  1640560003  1640992010  TIMEOUT      0:0   \n\n  reservation partprepaid node_num_in_rack rack  \n0                       0                5   13  \n1                       0               27   14  \n2                       0               12   15  \n3                       0               14   10  \n4                       0               30   10  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>start_date</th>\n      <th>end_date</th>\n      <th>node</th>\n      <th>nodetypes</th>\n      <th>numnodes</th>\n      <th>numcores</th>\n      <th>sharednode</th>\n      <th>submit</th>\n      <th>start</th>\n      <th>end</th>\n      <th>state</th>\n      <th>exitcode</th>\n      <th>reservation</th>\n      <th>partprepaid</th>\n      <th>node_num_in_rack</th>\n      <th>rack</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>2021-12-26 22:06:31</td>\n      <td>2021-12-31 22:06:50</td>\n      <td>r13n5</td>\n      <td>normal(1)</td>\n      <td>1</td>\n      <td>16</td>\n      <td>0</td>\n      <td>1640538678</td>\n      <td>1640559991</td>\n      <td>1640992010</td>\n      <td>TIMEOUT</td>\n      <td>0:0</td>\n      <td></td>\n      <td>0</td>\n      <td>5</td>\n      <td>13</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>2021-12-26 22:06:43</td>\n      <td>2021-12-31 22:06:50</td>\n      <td>r14n27</td>\n      <td>normal(1)</td>\n      <td>1</td>\n      <td>16</td>\n      <td>0</td>\n      <td>1640538678</td>\n      <td>1640560003</td>\n      <td>1640992010</td>\n      <td>TIMEOUT</td>\n      <td>0:0</td>\n      <td></td>\n      <td>0</td>\n      <td>27</td>\n      <td>14</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>2021-12-26 22:06:43</td>\n      <td>2021-12-31 22:06:50</td>\n      <td>r15n12</td>\n      <td>normal(1)</td>\n      <td>1</td>\n      <td>16</td>\n      <td>0</td>\n      <td>1640538678</td>\n      <td>1640560003</td>\n      <td>1640992010</td>\n      <td>TIMEOUT</td>\n      <td>0:0</td>\n      <td></td>\n      <td>0</td>\n      <td>12</td>\n      <td>15</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>2021-12-26 22:06:43</td>\n      <td>2021-12-31 22:06:50</td>\n      <td>r10n14</td>\n      <td>normal(1)</td>\n      <td>1</td>\n      <td>16</td>\n      <td>0</td>\n      <td>1640538678</td>\n      <td>1640560003</td>\n      <td>1640992010</td>\n      <td>TIMEOUT</td>\n      <td>0:0</td>\n      <td></td>\n      <td>0</td>\n      <td>14</td>\n      <td>10</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5</td>\n      <td>2021-12-26 22:06:43</td>\n      <td>2021-12-31 22:06:50</td>\n      <td>r10n30</td>\n      <td>normal(1)</td>\n      <td>1</td>\n      <td>16</td>\n      <td>0</td>\n      <td>1640538678</td>\n      <td>1640560003</td>\n      <td>1640992010</td>\n      <td>TIMEOUT</td>\n      <td>0:0</td>\n      <td></td>\n      <td>0</td>\n      <td>30</td>\n      <td>10</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_surf_slurm_reduced = df_surf_slurm.head(5)\n",
    "df_surf_slurm_reduced_copy = df_surf_slurm_reduced.copy()\n",
    "start = 'r'\n",
    "end = 'n'\n",
    "# create node and rack designations in the data-frame\n",
    "df_surf_slurm_reduced_copy['node_num_in_rack'] = df_surf_slurm_reduced_copy['node'].apply(lambda x: x[x.find(end)+1:])\n",
    "df_surf_slurm_reduced_copy['rack'] = df_surf_slurm_reduced_copy['node'].apply(lambda x: x[x.find(start)+1:x.find(end)])\n",
    "# Print the final reduced dataframe\n",
    "df_surf_slurm_reduced_copy"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-21T22:37:53.466004200Z",
     "start_time": "2023-08-21T22:37:53.247241400Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "outputs": [],
   "source": [
    "# df_surf_slurm['reservation'].unique()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-21T22:37:53.466004200Z",
     "start_time": "2023-08-21T22:37:53.278540200Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "outputs": [],
   "source": [
    "onto = get_ontology(\"https://example.org/hpcontology_surf.owl#\")\n",
    "with onto:\n",
    "    class Hardware(Thing): pass\n",
    "    class Computer(Hardware): pass\n",
    "    class Cluster(Computer): pass\n",
    "    class Rack(Hardware): pass\n",
    "    class Server(Computer): pass\n",
    "    class Processor(Hardware): pass\n",
    "    class CPU(Processor): pass\n",
    "    class Coprocessor(Processor): pass\n",
    "    class Accelerator(Coprocessor): pass\n",
    "    class GPU(Accelerator): pass\n",
    "    class Memory(Hardware): pass\n",
    "    class Concept(Thing): pass\n",
    "    class Entity(Concept): pass\n",
    "    class Site(Entity): pass\n",
    "    class Artifact(Thing): pass\n",
    "    class Data(Artifact): pass\n",
    "    class Software(Entity): pass\n",
    "    class MonitoringSystem(Software): pass\n",
    "    class MetricsExporter(Software): pass\n",
    "    class MonitoringMetrics(Data): pass\n",
    "    class ResourceManager(Software): pass\n",
    "    class JobScheduler(Software): pass\n",
    "    class Job(Data): pass\n",
    "    class Resource(Entity): pass\n",
    "    class Feature(Thing): pass\n",
    "    class Property(MonitoringMetrics): pass\n",
    "    class MetricCollector(Feature): pass"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-21T22:37:53.466004200Z",
     "start_time": "2023-08-21T22:37:53.309738100Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "outputs": [],
   "source": [
    "# refer to this source for knowing more about time-series modelling in owl - https://docs.ogc.org/is/15-043r3/15-043r3.html#16\n",
    "onto = get_ontology(\"https://example.org/hpcontology_surf.owl#\")\n",
    "with onto:\n",
    "    class hasMember(Thing >> Thing) : pass\n",
    "    class memberOf(Thing >> Thing) :\n",
    "        inverse = hasMember\n",
    "    class member(ObjectProperty):\n",
    "        domain = [Thing]\n",
    "        range = [Thing]\n",
    "        equivalent_to = [hasMember]\n",
    "        inverse = memberOf\n",
    "    class featureOfInterest(Thing >> Feature): pass\n",
    "    class manageJob(Software >> Job): pass\n",
    "    class hasMonitoringSystem(Computer >> MonitoringSystem): pass\n",
    "    class hasMetricsExporter(Entity >> MetricsExporter): pass\n",
    "    class exportMonitoringMetrics(MetricsExporter >> MonitoringMetrics): pass\n",
    "    class observedProperty(Thing >> Property): pass\n",
    "    class generatedAtTime(Thing >> datetime.datetime): pass\n",
    "\n",
    "    hpc_cluster = Cluster()\n",
    "    prometheus = MonitoringSystem()\n",
    "    prometheus_node_exporter = MetricsExporter()\n",
    "    monitoring_metrics = MonitoringMetrics()\n",
    "    hpc_cluster.hasMonitoringSystem.append(prometheus)\n",
    "    prometheus.hasMetricsExporter.append(prometheus_node_exporter)\n",
    "    prometheus_node_exporter.exportMonitoringMetrics.append(monitoring_metrics)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-21T22:37:53.466004200Z",
     "start_time": "2023-08-21T22:37:53.325367700Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "outputs": [],
   "source": [
    "# Iterate through the corresponding metric's data-frame and create OWL2 individuals accordingly\n",
    "# we are considering only first-row elements in this case, but this idea can be extended for the remaining elements of the dataframe\n",
    "onto = get_ontology(\"https://example.org/hpcontology_surf.owl#\")\n",
    "with onto:\n",
    "    class hasMeasurementIdentifier(MonitoringMetrics >> int): pass\n",
    "    monitoring_metrics.hasMeasurementIdentifier.append(int(df_surf_reduced_copy['id'].iloc[0]))\n",
    "    monitoring_metrics.generatedAtTime.append(df_surf_reduced_copy['timestamp'].iloc[0].to_pydatetime())\n",
    "    # monitoring_metrics.label.append(\"Measurement has datetime-format values\")\n",
    "    monitoring_metrics.comment = [\"Timestamp of the event/measurement (every 30 seconds)\"]\n",
    "\n",
    "    class measuresValueOfThing(MonitoringMetrics >> Thing): pass\n",
    "    class DataCentre(Site): pass\n",
    "    datacentre = DataCentre()\n",
    "    monitoring_metrics.measuresValueOfThing.append(datacentre)\n",
    "\n",
    "    class AmbientTemperature(Property): pass\n",
    "    ambient_temperature = AmbientTemperature()\n",
    "    datacentre.observedProperty.append(ambient_temperature)\n",
    "    class hasTemperatureValue(Feature >> float): pass\n",
    "    ambient_temperature.hasTemperatureValue.append(float(df_surf_reduced_copy['surfsara_ambient_temp'].iloc[0]))\n",
    "    ambient_temperature.comment = [\"Temperature of the datacentre\"]\n",
    "\n",
    "    class PowerUsage(Property): pass\n",
    "    power_usage = PowerUsage()\n",
    "    datacentre.observedProperty.append(power_usage)\n",
    "    class hasPowerUsageValue(Property >> float): pass\n",
    "    power_usage.hasPowerUsageValue.append(float(df_surf_reduced_copy['surfsara_power_usage'].iloc[0]))\n",
    "    power_usage.comment = [\"Power usage for the datacentre\"]\n",
    "\n",
    "    individual = Server(int(df_surf_reduced_copy['node_num_in_rack'].iloc[0]))\n",
    "    rack = Rack(int(df_surf_reduced_copy['rack'].iloc[0]))\n",
    "    class atLocation(Thing >> Thing): pass\n",
    "    monitoring_metrics.measuresValueOfThing.append(individual)\n",
    "    individual.atLocation.append(rack)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-21T22:37:53.466004200Z",
     "start_time": "2023-08-21T22:37:53.340993Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "outputs": [],
   "source": [
    "onto = get_ontology(\"https://example.org/hpcontology_surf.owl#\")\n",
    "with onto:\n",
    "    class DeviceStatus(Property): pass\n",
    "    class hasUpValue(Property >> float): pass\n",
    "    class TimeSinceEpoch(Property): pass\n",
    "    class hasTimeSinceEpochValue(Property >> datetime.datetime): pass\n",
    "\n",
    "    individual = Server(int(df_surf_reduced_copy['node_num_in_rack'].iloc[0]))\n",
    "    device_status = DeviceStatus()\n",
    "    individual.observedProperty.append(device_status)\n",
    "    device_status.hasUpValue.append(float(df_surf_reduced_copy['up'].iloc[0]))\n",
    "    device_status.comment = [\"Shows whether the node is up or not\"]\n",
    "\n",
    "    time_since_epoch = TimeSinceEpoch()\n",
    "    individual.observedProperty.append(time_since_epoch)\n",
    "    time_since_epoch.hasTimeSinceEpochValue.append(datetime.datetime.fromtimestamp(df_surf_reduced_copy['node_time_seconds'].iloc[0]))\n",
    "    time_since_epoch.comment = [\"Parsed from system time in seconds since epoch (1970)\"]\n",
    "\n",
    "    class Motherboard(Hardware): pass\n",
    "    class ThermalZone(Feature): pass\n",
    "    class Temperature(Property): pass\n",
    "    class hasTemperatureValue(Property >> float): pass\n",
    "    motherboard = Motherboard()\n",
    "    temperature = Temperature()\n",
    "    thermal_zone = ThermalZone()\n",
    "    individual.hasMember.append(motherboard)\n",
    "    motherboard.featureOfInterest.append(thermal_zone)\n",
    "    thermal_zone.observedProperty.append(temperature)\n",
    "    temperature.hasTemperatureValue.append(float(df_surf_reduced_copy['node_thermal_zone_temp-mean'].iloc[0]))\n",
    "    temperature.label.append(\"Measured in Celsius\")\n",
    "    temperature.comment = [\"The (mean) thermal zone temperature of the node; also aggregated as max and min (which are not represented in the ontology for brevity)\"]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-21T22:37:53.466004200Z",
     "start_time": "2023-08-21T22:37:53.356618100Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "outputs": [],
   "source": [
    "onto = get_ontology(\"https://example.org/hpcontology_surf.owl#\")\n",
    "with onto:\n",
    "    class SystemStatisticsCollector(MetricCollector): pass\n",
    "    system_stats = SystemStatisticsCollector()\n",
    "    class ProcessesBlocked(Property): pass\n",
    "    processes_blocked = ProcessesBlocked()\n",
    "    class hasNumberOfProcessesBlockedValue(Property >> float): pass\n",
    "    system_stats.observedProperty.append(processes_blocked)\n",
    "    processes_blocked.hasNumberOfProcessesBlockedValue.append(float(df_surf_reduced_copy['node_procs_blocked'].iloc[0]))\n",
    "    processes_blocked.comment = [\"Number of processes blocked waiting for I/O to complete\"]\n",
    "\n",
    "    class ProcessesRunning(Property): pass\n",
    "    processes_running = ProcessesRunning()\n",
    "    system_stats.observedProperty.append(processes_running)\n",
    "    class hasNumberOfProcessesRunningValue(Property >> float): pass\n",
    "    processes_running.hasNumberOfProcessesRunningValue.append(float(df_surf_reduced_copy['node_procs_running'].iloc[0]))\n",
    "    processes_running.comment = [\"Number of processes in runnable state\"]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-21T22:37:53.466004200Z",
     "start_time": "2023-08-21T22:37:53.387900200Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "outputs": [],
   "source": [
    "onto = get_ontology(\"https://example.org/hpcontology_surf.owl#\")\n",
    "with onto:\n",
    "    class MemoryStatisticsCollector(MetricCollector): pass\n",
    "    memory_stats = MemoryStatisticsCollector()\n",
    "    class ActiveBytes(Property): pass\n",
    "    active_bytes = ActiveBytes()\n",
    "    class hasActiveBytesValue(Property >> float): pass\n",
    "    memory_stats.observedProperty.append(active_bytes)\n",
    "    active_bytes.hasActiveBytesValue.append(float(df_surf_reduced_copy['node_memory_Active_bytes'].iloc[0]))\n",
    "    active_bytes.comment = [\"Memory information field Active_bytes\"]\n",
    "\n",
    "    class DirtyBytes(Property): pass\n",
    "    dirty_bytes = DirtyBytes()\n",
    "    class hasDirtyBytesValue(Property >> float): pass\n",
    "    memory_stats.observedProperty.append(dirty_bytes)\n",
    "    dirty_bytes.hasDirtyBytesValue.append(float(df_surf_reduced_copy['node_memory_Dirty_bytes'].iloc[0]))\n",
    "    dirty_bytes.comment = [\"Memory information field Dirty_bytes (Contains the amount of dirty memory at which a process generating disk writes will itself start writeback)\"]\n",
    "\n",
    "    class MemFreeBytes(Property): pass\n",
    "    mem_free_bytes = MemFreeBytes()\n",
    "    class hasMemFreeBytesValue(Property >> float): pass\n",
    "    memory_stats.observedProperty.append(mem_free_bytes)\n",
    "    mem_free_bytes.hasMemFreeBytesValue.append(float(df_surf_reduced_copy['node_memory_MemFree_bytes'].iloc[0]))\n",
    "    mem_free_bytes.comment = [\"Memory information field MemFree_bytes\"]\n",
    "\n",
    "    class PerCPUBytes(Property): pass\n",
    "    per_cpu_bytes = PerCPUBytes()\n",
    "    class hasPerCPUBytesValue(Property >> float): pass\n",
    "    memory_stats.observedProperty.append(per_cpu_bytes)\n",
    "    per_cpu_bytes.hasPerCPUBytesValue.append(float(df_surf_reduced_copy['node_memory_Percpu_bytes'].iloc[0]))\n",
    "    per_cpu_bytes.comment = [\"Memory information field Percpu_bytes\"]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-21T22:37:53.528492Z",
     "start_time": "2023-08-21T22:37:53.403490500Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "outputs": [],
   "source": [
    "onto = get_ontology(\"https://example.org/hpcontology_surf.owl#\")\n",
    "with onto:\n",
    "    class DiskIOStatisticsCollector(MetricCollector): pass\n",
    "    disk_stats = DiskIOStatisticsCollector()\n",
    "    class NumberOfIOs(Property): pass\n",
    "    num_ios = NumberOfIOs()\n",
    "    class hasNumberOfIOsInProgressValue(Property >> float): pass\n",
    "    disk_stats.observedProperty.append(num_ios)\n",
    "    num_ios.hasNumberOfIOsInProgressValue.append(float(df_surf_reduced_copy['node_disk_io_now-sum'].iloc[0]))\n",
    "    num_ios.comment = [\"The number of I/Os currently in progress (sum)\"]\n",
    "\n",
    "    class TotalWrites(Property): pass\n",
    "    total_writes = TotalWrites()\n",
    "    class hasTotalNumberOfWritesCompletedValue(Property >> float): pass\n",
    "    disk_stats.observedProperty.append(total_writes)\n",
    "    total_writes.hasTotalNumberOfWritesCompletedValue.append(float(df_surf_reduced_copy['node_disk_writes_completed_total-sum'].iloc[0]))\n",
    "    total_writes.comment = [\"The total number of writes completed successfully (sum)\"]\n",
    "\n",
    "    class ReadBytes(Property): pass\n",
    "    read_bytes = ReadBytes()\n",
    "    class hasTotalNumberOfReadBytesValue(Property >> float): pass\n",
    "    disk_stats.observedProperty.append(read_bytes)\n",
    "    read_bytes.hasTotalNumberOfReadBytesValue.append(float(df_surf_reduced_copy['node_disk_read_bytes_total-sum'].iloc[0]))\n",
    "    read_bytes.comment = [\"The total number of bytes read successfully (sum)\"]\n",
    "\n",
    "    class WrittenBytes(Property): pass\n",
    "    written_bytes = WrittenBytes()\n",
    "    class hasTotalNumberOfWrittenBytesValue(Property >> float): pass\n",
    "    disk_stats.observedProperty.append(written_bytes)\n",
    "    written_bytes.hasTotalNumberOfWrittenBytesValue.append(float(df_surf_reduced_copy['node_disk_written_bytes_total-sum'].iloc[0]))\n",
    "    written_bytes.comment = [\"The total number of bytes written successfully (sum)\"]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-21T22:37:53.590995600Z",
     "start_time": "2023-08-21T22:37:53.434761100Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "outputs": [],
   "source": [
    "onto = get_ontology(\"https://example.org/hpcontology_surf.owl#\")\n",
    "with onto:\n",
    "    class HardwareMonitor(MetricCollector): pass\n",
    "    hardware_monitor = HardwareMonitor()\n",
    "    class NodeTemperature(Property): pass\n",
    "    node_temperature = NodeTemperature()\n",
    "    class hasNodeTemperatureValue(Property >> float): pass\n",
    "    hardware_monitor.observedProperty.append(node_temperature)\n",
    "    node_temperature.hasNodeTemperatureValue.append(float(df_surf_reduced_copy['node_hwmon_temp_celsius-mean'].iloc[0]))\n",
    "    node_temperature.label.append(\"Measured in Celsius\")\n",
    "    node_temperature.comment = [\"Temperature of the node (mean); also aggregated as max and min (which are not represented in the ontology for brevity)\"]\n",
    "\n",
    "    class CPULoadCollector(MetricCollector): pass\n",
    "    cpu_load_collector = CPULoadCollector()\n",
    "    class CPULoadAverage(Property): pass\n",
    "    cpu_load_average = CPULoadAverage()\n",
    "    class hasCPULoadAverageValue(Property >> float): pass\n",
    "    cpu_load_collector.observedProperty.append(cpu_load_average)\n",
    "    cpu_load_average.hasCPULoadAverageValue.append(float(df_surf_reduced_copy['node_load1'].iloc[0]))\n",
    "    cpu_load_average.comment = [\"1m load average; also aggregated at 5m and 15m (which are not represented in the ontology for brevity)\"]\n",
    "\n",
    "    class ARPMetricCollector(MetricCollector): pass\n",
    "    arp_collector = ARPMetricCollector()\n",
    "    class ARPEntries(Property): pass\n",
    "    arp_entries = ARPEntries()\n",
    "    class hasArpEntriesValue(Property >> float): pass\n",
    "    arp_collector.observedProperty.append(arp_entries)\n",
    "    arp_entries.hasArpEntriesValue.append(float(df_surf_reduced_copy['node_arp_entries-sum'].iloc[0]))\n",
    "    arp_entries.comment = [\"ARP entries by device (sum)\"]\n",
    "\n",
    "    class BootTimeMetricCollector(MetricCollector): pass\n",
    "    boot_time_collector = BootTimeMetricCollector()\n",
    "    class BootTime(Property): pass\n",
    "    boot_time = BootTime()\n",
    "    class hasBootTimeValue(Property >> float): pass\n",
    "    boot_time_collector.observedProperty.append(boot_time)\n",
    "    boot_time.hasBootTimeValue.append(float(df_surf_reduced_copy['node_boot_time_seconds'].iloc[0]))\n",
    "    boot_time.comment = [\"Node boot time, in unixtime\"]\n",
    "\n",
    "    class EnergyUsageMetricCollector(MetricCollector): pass\n",
    "    energy_usage_collector = EnergyUsageMetricCollector()\n",
    "    class RunningAveragePowerLimit(Property): pass\n",
    "    rapl = RunningAveragePowerLimit()\n",
    "    class hasRAPLPackageValue(Property >> float): pass\n",
    "    energy_usage_collector.observedProperty.append(rapl)\n",
    "    rapl.hasRAPLPackageValue.append(float(df_surf_reduced_copy['node_rapl_package_joules_total-sum'].iloc[0]))\n",
    "    rapl.comment = [\"Current RAPL (Running Average Power Limit) package value in joules (sum)\"]\n",
    "\n",
    "    class UDPQueuesCollector(MetricCollector): pass\n",
    "    udp_queues_collector = UDPQueuesCollector()\n",
    "    class UDPQueues(Property): pass\n",
    "    udp_queues = UDPQueues()\n",
    "    class hasAllocatedMemoryForUDPDatagramsValue(Property >> float): pass\n",
    "    udp_queues_collector.observedProperty.append(udp_queues)\n",
    "    udp_queues.hasAllocatedMemoryForUDPDatagramsValue.append(float(df_surf_reduced_copy['node_udp_queues-sum'].iloc[0]))\n",
    "    udp_queues.comment = [\"Number of allocated memory in the kernel for UDP datagrams in bytes (sum)\"]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-21T22:37:53.653509100Z",
     "start_time": "2023-08-21T22:37:53.466004200Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "outputs": [],
   "source": [
    "onto = get_ontology(\"https://example.org/hpcontology_surf.owl#\")\n",
    "with onto:\n",
    "    class VirtualMemoryStatisticsCollector(MetricCollector): pass\n",
    "    vmstats = VirtualMemoryStatisticsCollector()\n",
    "\n",
    "    class ContextSwitches(Property): pass\n",
    "    context_switches = ContextSwitches()\n",
    "    class hasTotalContextSwitchesValue(Property >> float): pass\n",
    "    vmstats.observedProperty.append(context_switches)\n",
    "    context_switches.hasNodeTemperatureValue.append(float(df_surf_reduced_copy['node_context_switches_total'].iloc[0]))\n",
    "    context_switches.comment = [\"Total number of context switches\"]\n",
    "\n",
    "    class Forks(Property): pass\n",
    "    forks = Forks()\n",
    "    class hasTotalForksValue(Property >> float): pass\n",
    "    vmstats.observedProperty.append(forks)\n",
    "    forks.hasTotalForksValue.append(float(df_surf_reduced_copy['node_forks_total'].iloc[0]))\n",
    "    forks.comment = [\"Total number of forks\"]\n",
    "\n",
    "    class Interrupts(Property): pass\n",
    "    interrupts = Interrupts()\n",
    "    class hasTotalInterruptsServicedValue(Property >> float): pass\n",
    "    vmstats.observedProperty.append(interrupts)\n",
    "    interrupts.hasTotalInterruptsServicedValue.append(float(df_surf_reduced_copy['node_intr_total'].iloc[0]))\n",
    "    interrupts.comment = [\"Total number of interrupts serviced\"]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-21T22:37:53.684738500Z",
     "start_time": "2023-08-21T22:37:53.497245Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "outputs": [],
   "source": [
    "onto = get_ontology(\"https://example.org/hpcontology_surf.owl#\")\n",
    "with onto:\n",
    "    class FileSystemMetricCollector(MetricCollector): pass\n",
    "    file_system = FileSystemMetricCollector()\n",
    "\n",
    "    class FilesFree(Property): pass\n",
    "    files_free = FilesFree()\n",
    "    class hasTotalFreeFileNodesValue(Property >> float): pass\n",
    "    file_system.observedProperty.append(files_free)\n",
    "    files_free.hasTotalFreeFileNodesValue.append(float(df_surf_reduced_copy['node_filesystem_files_free-sum'].iloc[0]))\n",
    "    files_free.comment = [\"Filesystem total free file nodes (sum)\"]\n",
    "\n",
    "    class Files(Property): pass\n",
    "    files = Files()\n",
    "    class hasTotalFileNodesValue(Property >> float): pass\n",
    "    file_system.observedProperty.append(files)\n",
    "    files.hasTotalFileNodesValue.append(float(df_surf_reduced_copy['node_filesystem_files-sum'].iloc[0]))\n",
    "    files.comment = [\"Filesystem total file nodes (sum)\"]\n",
    "\n",
    "    class FreeSpace(Property): pass\n",
    "    free_space = FreeSpace()\n",
    "    class hasTotalFreeSpaceValue(Property >> float): pass\n",
    "    file_system.observedProperty.append(free_space)\n",
    "    free_space.hasTotalFreeSpaceValue.append(float(df_surf_reduced_copy['node_filesystem_free_bytes-sum'].iloc[0]))\n",
    "    free_space.comment = [\"Filesystem free space in bytes (sum)\"]\n",
    "\n",
    "    class DeviceErrorReport(Property): pass\n",
    "    device_error = DeviceErrorReport()\n",
    "    class hasDeviceErrorValue(Property >> float): pass\n",
    "    file_system.observedProperty.append(device_error)\n",
    "    device_error.hasDeviceErrorValue.append(float(df_surf_reduced_copy['node_filesystem_device_error-sum'].iloc[0]))\n",
    "    device_error.comment = [\"Whether an error occurred while getting statistics for the given device (sum)\"]\n",
    "\n",
    "    class FileSystemSpace(Property): pass\n",
    "    file_system_space = FileSystemSpace()\n",
    "    class hasAvailableFileSystemSpaceToNonRootUsersValue(Property >> float): pass\n",
    "    file_system.observedProperty.append(file_system_space)\n",
    "    file_system_space.hasAvailableFileSystemSpaceToNonRootUsersValue.append(float(df_surf_reduced_copy['node_filesystem_avail_bytes-sum'].iloc[0]))\n",
    "    file_system_space.comment = [\"Filesystem space available to non-root users in bytes (sum)\"]\n",
    "\n",
    "    class FileSystemSize(Property): pass\n",
    "    file_system_size = FileSystemSize()\n",
    "    class hasFileSystemSizeValue(Property >> float): pass\n",
    "    file_system.observedProperty.append(file_system_size)\n",
    "    file_system_size.hasFileSystemSizeValue.append(float(df_surf_reduced_copy['node_filesystem_size_bytes-sum'].iloc[0]))\n",
    "    file_system_size.comment = [\"Filesystem size in bytes (sum)\"]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-21T22:37:53.684738500Z",
     "start_time": "2023-08-21T22:37:53.512865500Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "outputs": [],
   "source": [
    "onto = get_ontology(\"https://example.org/hpcontology_surf.owl#\")\n",
    "with onto:\n",
    "    class GPUDevice(Feature): pass\n",
    "    gpu = GPU()\n",
    "    gpu_device = GPUDevice()\n",
    "    individual = Server(int(df_surf_reduced_copy['node_num_in_rack'].iloc[0]))\n",
    "    individual.hasMember.append(gpu)\n",
    "    gpu.featureOfInterest.append(gpu_device)\n",
    "\n",
    "    class FanSpeed(Property): pass\n",
    "    class hasFanSpeedValue(Property >> float): pass\n",
    "    fan_speed = FanSpeed()\n",
    "    gpu_device.observedProperty.append(fan_speed)\n",
    "    fan_speed.hasFanSpeedValue.append(float(df_surf_reduced_copy['nvidia_gpu_fanspeed_percent-mean'].iloc[0]))\n",
    "    fan_speed.comment = [\"Fanspeed of the GPU device as a percent of its maximum (mean); also aggregated as max and min (which are not represented in the ontology for brevity)\"]\n",
    "\n",
    "    class Temperature(Property): pass\n",
    "    class hasTemperatureValue(Property >> float): pass\n",
    "    temperature = Temperature()\n",
    "    gpu_device.observedProperty.append(temperature)\n",
    "    temperature.hasTemperatureValue.append(float(df_surf_reduced_copy['nvidia_gpu_temperature_celsius-mean'].iloc[0]))\n",
    "    temperature.comment = [\"Temperature of the GPU device in Celsius (mean); also aggregated as max and min (which are not represented in the ontology for brevity)\"]\n",
    "\n",
    "    class PowerUsage(Property): pass\n",
    "    class hasPowerUsageValue(Property >> float): pass\n",
    "    power_usage = PowerUsage()\n",
    "    gpu_device.observedProperty.append(power_usage)\n",
    "    power_usage.hasPowerUsageValue.append(float(df_surf_reduced_copy['nvidia_gpu_power_usage_milliwatts-mean'].iloc[0]))\n",
    "    power_usage.comment = [\"Power usage of the GPU device in milliwatts (mean); also aggregated as sum, max and min (which are not represented in the ontology for brevity)\"]\n",
    "\n",
    "    class DutyCycle(Property): pass\n",
    "    class hasDutyCycleValue(Property >> float): pass\n",
    "    duty_cycle = DutyCycle()\n",
    "    gpu_device.observedProperty.append(duty_cycle)\n",
    "    duty_cycle.hasDutyCycleValue.append(float(df_surf_reduced_copy['nvidia_gpu_duty_cycle-mean'].iloc[0]))\n",
    "    duty_cycle.comment = [\"Percent of time over the past sample period during which one or more kernels were executing on the GPU device (mean); also aggregated as max and min (which are not represented in the ontology for brevity)\"]\n",
    "\n",
    "    class Memory(Property): pass\n",
    "    class hasMemoryUsedValue(Property >> float): pass\n",
    "    memory = Memory()\n",
    "    gpu_device.observedProperty.append(memory)\n",
    "    memory.hasMemoryUsedValue.append(float(df_surf_reduced_copy['nvidia_gpu_memory_used_bytes-sum'].iloc[0]))\n",
    "    memory.comment = [\"Memory used by the GPU device in bytes (sum)\"]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-21T22:37:53.762900200Z",
     "start_time": "2023-08-21T22:37:53.544118Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "outputs": [],
   "source": [
    "onto = get_ontology(\"https://example.org/hpcontology_surf.owl#\")\n",
    "with onto:\n",
    "    class NetworkInterface(Feature): pass\n",
    "    network_interface = NetworkInterface()\n",
    "    individual = Server(int(df_surf_reduced_copy['node_num_in_rack'].iloc[0]))\n",
    "    individual.featureOfInterest.append(network_interface)\n",
    "    class NetworkInterfaceMetrics(Property): pass\n",
    "    network_interface_metrics = NetworkInterfaceMetrics()\n",
    "    network_interface.observedProperty.append(network_interface_metrics)\n",
    "\n",
    "    class hasReceiveBytesTotal(Property >> float): pass\n",
    "    network_interface_metrics.hasReceiveBytesTotal.append(float(df_surf_reduced_copy['node_network_receive_bytes_total-sum'].iloc[0]))\n",
    "    network_interface_metrics.comment = [\"hasReceiveBytesTotal → Network device statistic receive_bytes (sum)\"]\n",
    "\n",
    "    class hasReceivePacketsTotal(Property >> float): pass\n",
    "    network_interface_metrics.hasReceivePacketsTotal.append(float(df_surf_reduced_copy['node_network_receive_packets_total-sum'].iloc[0]))\n",
    "    network_interface_metrics.comment += [\"\\nhasReceivePacketsTotal → Network device statistic receive_packets (sum)\"]\n",
    "\n",
    "    class hasReceiveMulticastPacketsTotal(Property >> float): pass\n",
    "    network_interface_metrics.hasReceiveMulticastPacketsTotal.append(float(df_surf_reduced_copy['node_network_receive_multicast_total-sum'].iloc[0]))\n",
    "    network_interface_metrics.comment += [\"\\nhasReceiveMulticastPacketsTotal → Network device statistic receive_multicast (sum)\"]\n",
    "\n",
    "    class hasReceiveDroppedPacketsTotal(Property >> float): pass\n",
    "    network_interface_metrics.hasReceiveDroppedPacketsTotal.append(float(df_surf_reduced_copy['node_network_receive_drop_total-sum'].iloc[0]))\n",
    "    network_interface_metrics.comment += [\"\\nhasReceiveDroppedPacketsTotal → Network device statistic receive_drop (sum)\"]\n",
    "    # comment[network_interface_metrics, hasReceiveDroppedPacketsTotal, float(df_surf_reduced_copy['node_network_receive_drop_total-sum'].iloc[0])] = [\"Network device statistic receive_drop (sum)\"]\n",
    "\n",
    "    class hasTransmitBytesTotal(Property >> float): pass\n",
    "    network_interface_metrics.hasTransmitBytesTotal.append(float(df_surf_reduced_copy['node_network_transmit_bytes_total-sum'].iloc[0]))\n",
    "    network_interface_metrics.comment += [\"\\nhasTransmitBytesTotal → Network device statistic transmit_bytes (sum)\"]\n",
    "\n",
    "    class hasTransmitPacketsTotal(Property >> float): pass\n",
    "    network_interface_metrics.hasTransmitPacketsTotal.append(float(df_surf_reduced_copy['node_network_transmit_packets_total-sum'].iloc[0]))\n",
    "    network_interface_metrics.comment += [\"\\nhasTransmitPacketsTotal → Network device statistic transmit_packets (sum)\"]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-21T22:37:53.762900200Z",
     "start_time": "2023-08-21T22:37:53.575366600Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "outputs": [],
   "source": [
    "onto = get_ontology(\"https://example.org/hpcontology_surf.owl#\")\n",
    "with onto:\n",
    "    class KernelNetworkSubsystem(Feature): pass\n",
    "    kernel_network_subsystem = KernelNetworkSubsystem()\n",
    "    individual = Server(int(df_surf_reduced_copy['node_num_in_rack'].iloc[0]))\n",
    "    individual.featureOfInterest.append(kernel_network_subsystem)\n",
    "    class ICMPMetrics(Property): pass\n",
    "    icmp_metrics = ICMPMetrics()\n",
    "    kernel_network_subsystem.observedProperty.append(icmp_metrics)\n",
    "    class TCPMetrics(Property): pass\n",
    "    tcp_metrics = TCPMetrics()\n",
    "    kernel_network_subsystem.observedProperty.append(tcp_metrics)\n",
    "    class UDPMetrics(Property): pass\n",
    "    udp_metrics = UDPMetrics()\n",
    "    kernel_network_subsystem.observedProperty.append(udp_metrics)\n",
    "\n",
    "    class hasICMPInErrorsMessagesValue(Property >> float): pass\n",
    "    icmp_metrics.hasICMPInErrorsMessagesValue.append(float(df_surf_reduced_copy['node_netstat_Icmp_InErrors'].iloc[0]))\n",
    "    icmp_metrics.comment = [\"hasICMPInErrorsMessagesValue → Statistic IcmpInErrors (The number of ICMP messages which the entity received but determined as having ICMP-specific errors (bad ICMP checksums, bad length, etc.))\"]\n",
    "    class hasICMPInMessagesValue(Property >> float): pass\n",
    "    icmp_metrics.hasICMPInMessagesValue.append(float(df_surf_reduced_copy['node_netstat_Icmp_InMsgs'].iloc[0]))\n",
    "    icmp_metrics.comment += [\"\\nhasICMPInMessagesValue → Statistic IcmpInMsgs (The number of ICMP messages which the node received)\"]\n",
    "    class hasICMPOutMessagesValue(Property >> float): pass\n",
    "    icmp_metrics.hasICMPOutMessagesValue.append(float(df_surf_reduced_copy['node_netstat_Icmp_OutMsgs'].iloc[0]))\n",
    "    icmp_metrics.comment += [\"\\nhasICMPOutMessagesValue → Statistic IcmpOutMsgs (The total number of ICMP messages which this entity attempted to send; note that this counter includes all those counted by icmpOutErrors)\"]\n",
    "\n",
    "    class hasTCPInErrorsSegmentsValue(Property >> float): pass\n",
    "    tcp_metrics.hasTCPInErrorsSegmentsValue.append(float(df_surf_reduced_copy['node_netstat_Tcp_InErrs'].iloc[0]))\n",
    "    tcp_metrics.comment = [\"\\nhasTCPInErrorsSegmentsValue → Statistic TcpInErrs (The total number of segments received in error (e.g., bad TCP checksums))\"]\n",
    "    class hasTCPInSegmentsValue(Property >> float): pass\n",
    "    tcp_metrics.hasTCPInSegmentsValue.append(float(df_surf_reduced_copy['node_netstat_Tcp_InSegs'].iloc[0]))\n",
    "    tcp_metrics.comment += [\"\\nhasTCPInSegmentsValue → Protocol Tcp statistic InSegs (The total number of segments received, including those received in error; this count includes segments received on currently established connections)\"]\n",
    "    class hasTCPOutSegmentsValue(Property >> float): pass\n",
    "    tcp_metrics.hasTCPOutSegmentsValue.append(float(df_surf_reduced_copy['node_netstat_Tcp_OutSegs'].iloc[0]))\n",
    "    tcp_metrics.comment += [\"\\nhasTCPOutSegmentsValue → Statistic TcpOutSegs (The total number of segments sent, including those on current connections but excluding those containing only retransmitted octets)\"]\n",
    "    class hasTCPRetransmittedSegmentsValue(Property >> float): pass\n",
    "    tcp_metrics.hasTCPRetransmittedSegmentsValue.append(float(df_surf_reduced_copy['node_netstat_Tcp_RetransSegs'].iloc[0]))\n",
    "    tcp_metrics.comment += [\"\\nhasTCPRetransmittedSegmentsValue → Statistic TcpRetransSegs (The total number of segments retransmitted - that is, the number of TCP segments transmitted containing one or more previously transmitted octets)\"]\n",
    "\n",
    "    class hasUDPInDatagramsValue(Property >> float): pass\n",
    "    udp_metrics.hasUDPInDatagramsValue.append(float(df_surf_reduced_copy['node_netstat_Udp_InDatagrams'].iloc[0]))\n",
    "    udp_metrics.comment = [\"\\nhasUDPInDatagramsValue → Statistic UdpInDatagrams (The total number of UDP datagrams delivered to UDP users of the node)\"]\n",
    "    class hasUDPOutDatagramsValue(Property >> float): pass\n",
    "    udp_metrics.hasUDPOutDatagramsValue.append(float(df_surf_reduced_copy['node_netstat_Udp_OutDatagrams'].iloc[0]))\n",
    "    udp_metrics.comment += [\"\\nhasUDPOutDatagramsValue → Statistic UdpOutDatagrams (The total number of UDP datagrams sent from this entity)\"]\n",
    "    class hasUDPInErrorsDatagramsValue(Property >> float): pass\n",
    "    udp_metrics.hasUDPInErrorsDatagramsValue.append(float(df_surf_reduced_copy['node_netstat_Udp_InErrors'].iloc[0]))\n",
    "    udp_metrics.comment += [\"\\nhasUDPInErrorsDatagramsValue → Statistic UdpInErrors (The number of received UDP datagrams that could not be delivered for reasons other than the lack of an application at the destination port)\"]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-21T22:37:53.841023300Z",
     "start_time": "2023-08-21T22:37:53.590995600Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "outputs": [],
   "source": [
    "# Slurm section\n",
    "onto = get_ontology(\"https://example.org/hpcontology_surf.owl#\")\n",
    "with onto:\n",
    "    class hasResourceManager(Computer >> ResourceManager): pass\n",
    "    class hasJobScheduler(Computer >> JobScheduler): pass\n",
    "    class managesJob(JobScheduler >> Job): pass\n",
    "    slurm = ResourceManager()\n",
    "    slurm_workload_manager = JobScheduler()\n",
    "    slurm.hasMember.append(slurm_workload_manager)\n",
    "    hpc_cluster.hasResourceManager.append(slurm)\n",
    "    hpc_cluster.hasJobScheduler.append(slurm_workload_manager)\n",
    "    job = Job()\n",
    "    slurm_workload_manager.managesJob.append(job)\n",
    "    class ExitCode(Data): pass\n",
    "    # Start modelling data-values in the ontology\n",
    "    class hasJobIdentifier(Job >> int): pass\n",
    "    job.hasJobIdentifier.append(int(df_surf_slurm_reduced_copy['id'].iloc[0]))\n",
    "    job.comment = [\"has Job-ID, of type integer\"]\n",
    "    class hasStartDate(Thing >> datetime.datetime): pass\n",
    "    job.hasStartDate.append(df_surf_slurm_reduced_copy['start_date'].iloc[0].to_pydatetime())\n",
    "    job.comment += [\"\\nhas start-date of job, of type datetime\"]\n",
    "    class hasEndDate(Thing >> datetime.datetime): pass\n",
    "    job.hasEndDate.append(df_surf_slurm_reduced_copy['end_date'].iloc[0].to_pydatetime())\n",
    "    job.comment += [\"\\nhas end-date of job, of type datetime\"]\n",
    "    class isScheduledOnServer(Thing >> Server): pass\n",
    "    individual = Server(int(df_surf_slurm_reduced_copy['node_num_in_rack'].iloc[0]))\n",
    "    rack = Rack(int(df_surf_slurm_reduced_copy['rack'].iloc[0]))\n",
    "    class atLocation(Thing >> Thing): pass\n",
    "    class isScheduledOn(Data >> Thing): pass\n",
    "    job.isScheduledOn.append(individual)\n",
    "    job.comment += [\"\\nis scheduled on the node (derived from 'node' value)\"]\n",
    "    individual.atLocation.append(rack)\n",
    "    individual.comment += [\"node is on the rack (derived from 'node' value)\"]\n",
    "    class hasNodeType(Server >> str): pass\n",
    "    individual.hasNodeType.append(str(df_surf_slurm_reduced_copy['nodetypes'].iloc[0] or ''))\n",
    "    individual.comment += [\"\\ntype of node\"]\n",
    "    class usesNode(Job >> int): pass\n",
    "    class usesCore(Job >> int): pass\n",
    "    job.usesNode.append(int(df_surf_slurm_reduced_copy['numnodes'].iloc[0]))\n",
    "    job.comment += [\"\\nNumber of nodes used for the job, of type integer\"]\n",
    "    job.usesCore.append(int(df_surf_slurm_reduced_copy['numcores'].iloc[0]))\n",
    "    job.comment += [\"\\nNumber of cores used for the job, of type integer\"]\n",
    "    class requiresSharedNode (Job >> str): pass\n",
    "    job.requiresSharedNode.append(str(df_surf_slurm_reduced_copy['sharednode'].iloc[0] or ''))\n",
    "    # job.comment = [\"\\nDescription unavailable\"]\n",
    "    class submittedAtTime(Job >> datetime.datetime): pass\n",
    "    class startedAtTime(Job >> datetime.datetime): pass\n",
    "    class endedAtTime(Job >> datetime.datetime): pass\n",
    "    job.submittedAtTime.append(datetime.datetime.fromtimestamp(int(df_surf_slurm_reduced_copy['submit'].iloc[0])))\n",
    "    job.comment += [\"\\nhas job submission time, of type timestamp\"]\n",
    "    job.startedAtTime.append(datetime.datetime.fromtimestamp(int(df_surf_slurm_reduced_copy['start'].iloc[0])))\n",
    "    job.comment += [\"\\nhas job start time, of type timestamp\"]\n",
    "    job.endedAtTime.append(datetime.datetime.fromtimestamp(int(df_surf_slurm_reduced_copy['end'].iloc[0])))\n",
    "    job.comment += [\"\\nhas job end time, of type timestamp\"]\n",
    "    class hasState (Job >> str): pass\n",
    "    job.hasState.append(str(df_surf_slurm_reduced_copy['state'].iloc[0] or ''))\n",
    "    job.comment += [\"\\nhas job end state, of type string\"]\n",
    "    exitCode = ExitCode()\n",
    "    class hasExitCode (Thing >> ExitCode): pass\n",
    "    job.hasExitCode.append(exitCode)\n",
    "    class hasExitCodeValue (Thing >> str, FunctionalProperty): pass\n",
    "    job.hasExitCodeValue = str(df_surf_slurm_reduced_copy['exitcode'].iloc[0])\n",
    "    job.comment += [\"\\nhas job exit code\"]\n",
    "    class hasReservationIdentifier(Job >> str): pass\n",
    "    job.hasReservationIdentifier.append(str(df_surf_slurm_reduced_copy['reservation'].iloc[0] or ''))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-21T22:37:53.841023300Z",
     "start_time": "2023-08-21T22:37:53.622284800Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "outputs": [],
   "source": [
    "file = \"hpcontology_surf.owl\"\n",
    "onto.save(file)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-21T22:37:53.841023300Z",
     "start_time": "2023-08-21T22:37:53.653509100Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "outputs": [],
   "source": [
    "# # Destroying ontology\n",
    "# onto = get_ontology(\"https://example.org/hpcontology_surf.owl#\")\n",
    "# onto.destroy()\n",
    "# file = \"hpcontology_surf.owl\"\n",
    "# os.remove(file)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-21T22:37:53.841023300Z",
     "start_time": "2023-08-21T22:37:53.669119500Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-21T22:37:53.903493900Z",
     "start_time": "2023-08-21T22:37:53.684738500Z"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
